<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vikas Pabba - Senior Software Engineer</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f9fafb;
        }

        /* Navigation Bar */
        nav {
            background: white;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 1000;
            padding: 1rem 0;
        }

        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .nav-brand {
            font-size: 1.5rem;
            font-weight: 700;
            color: #667eea;
            text-decoration: none;
        }

        .nav-links {
            display: flex;
            gap: 2rem;
            list-style: none;
        }

        .nav-links a {
            color: #555;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }

        .nav-links a:hover {
            color: #667eea;
        }

        /* Hero Section */
        .hero {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 6rem 2rem;
            text-align: center;
        }

        .hero h1 {
            font-size: 3.5rem;
            margin-bottom: 1rem;
        }

        .hero p {
            font-size: 1.3rem;
            margin-bottom: 2rem;
            opacity: 0.95;
        }

        .hero-buttons {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .btn {
            padding: 12px 30px;
            border-radius: 50px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s;
            display: inline-block;
        }

        .btn-primary {
            background: white;
            color: #667eea;
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(0,0,0,0.2);
        }

        .btn-secondary {
            background: rgba(255,255,255,0.2);
            color: white;
            border: 2px solid white;
        }

        .btn-secondary:hover {
            background: rgba(255,255,255,0.3);
        }

        /* Container */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 4rem 2rem;
        }

        section {
            margin-bottom: 4rem;
        }

        h2 {
            font-size: 2.5rem;
            margin-bottom: 2rem;
            color: #667eea;
        }

        .about-text {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #555;
        }

        /* Skills Grid */
        .skills-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 2rem;
        }

        .skill-category {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .skill-category h3 {
            color: #667eea;
            margin-bottom: 1rem;
        }

        .skill-category ul {
            list-style: none;
        }

        .skill-category li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
        }

        .skill-category li:before {
            content: "‚úì";
            position: absolute;
            left: 0;
            color: #667eea;
        }

        /* Experience */
        .experience-item {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .experience-header {
            display: flex;
            justify-content: space-between;
            margin-bottom: 1rem;
            flex-wrap: wrap;
        }

        .experience-title {
            font-size: 1.5rem;
            color: #667eea;
            font-weight: 600;
        }

        .experience-company {
            color: #555;
            font-size: 1.1rem;
        }

        .experience-date {
            color: #764ba2;
            font-weight: 600;
        }

        .experience-item ul {
            margin-left: 1.5rem;
        }

        .experience-item li {
            margin-bottom: 0.8rem;
            color: #555;
        }

        /* Projects */
        .project-card {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-left: 5px solid #667eea;
            transition: all 0.3s;
        }

        .project-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.2);
        }

        .project-card h3 {
            color: #667eea;
            font-size: 1.8rem;
            margin-bottom: 0.5rem;
        }

        .project-tech {
            color: #666;
            font-style: italic;
            margin-bottom: 1rem;
            font-size: 0.95rem;
        }

        .project-brief {
            color: #555;
            margin-bottom: 1rem;
            font-size: 1.05rem;
            line-height: 1.6;
        }

        .project-highlights {
            margin-left: 1.5rem;
            margin-bottom: 1rem;
        }

        .project-highlights li {
            margin-bottom: 0.6rem;
            color: #555;
        }

        .project-dataset {
            background: #f9fafb;
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
            border-left: 3px solid #764ba2;
            font-size: 0.95rem;
        }

        .github-link {
            color: #667eea;
            text-decoration: none;
            font-weight: 600;
            display: inline-block;
            margin-top: 1rem;
        }

        .github-link:hover {
            color: #764ba2;
        }

        /* Education */
        .education-item {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 1.5rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        /* Contact */
        .contact-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 4rem 2rem;
            border-radius: 10px;
            text-align: center;
        }

        .contact-section h2 {
            color: white;
        }

        .contact-links {
            display: flex;
            justify-content: center;
            gap: 2rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }

        .contact-links a {
            color: white;
            background: rgba(255,255,255,0.2);
            padding: 12px 25px;
            border-radius: 50px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s;
        }

        .contact-links a:hover {
            background: rgba(255,255,255,0.3);
            transform: translateY(-2px);
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 2rem;
            color: #666;
        }

        /* Smooth scrolling */
        html {
            scroll-behavior: smooth;
        }

        @media (max-width: 768px) {
            .nav-links {
                gap: 1rem;
                font-size: 0.9rem;
            }

            .hero h1 {
                font-size: 2.5rem;
            }

            .skills-grid {
                grid-template-columns: 1fr;
            }

            .experience-header {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <!-- Navigation Bar -->
    <nav>
        <div class="nav-container">
            <a href="#" class="nav-brand">Vikas Pabba</a>
            <ul class="nav-links">
                <li><a href="#about">About</a></li>
                <li><a href="#experience">Experience</a></li>
                <li><a href="#projects">Projects</a></li>
                <li><a href="#skills">Skills</a></li>
                <li><a href="#education">Education</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero">
        <h1>Hi, I'm Vikas Pabba</h1>
        <p>Senior Software Engineer | 4+ years in Big Data & Distributed Systems</p>
        <div class="hero-buttons">
            <a href="#projects" class="btn btn-primary">View My Work</a>
            <a href="resume.pdf" class="btn btn-secondary" download>Download Resume</a>
            <a href="#contact" class="btn btn-secondary">Get In Touch</a>
        </div>
    </section>

    <!-- Main Container -->
    <div class="container">
        <!-- About Section -->
        <section id="about">
            <h2>About Me</h2>
            <p class="about-text">
                I'm a Senior Software Engineer with 4+ years of experience specializing in big data technologies and distributed systems. I architect and build scalable data pipelines that process millions of records daily using Apache Spark, Apache Airflow, and modern cloud platforms.
                <br><br>
                My expertise spans the entire data engineering stack - from designing robust ETL pipelines and implementing real-time streaming architectures to deploying ML models in production. I've successfully delivered enterprise-scale solutions on AWS, GCP, and Azure, consistently achieving 99.9%+ uptime while optimizing performance and reducing costs by up to 35%.
                <br><br>
                I'm passionate about solving complex data challenges and building systems that can handle massive scale. When I'm not coding, you'll find me exploring new technologies, contributing to open-source projects, or mentoring aspiring data engineers.
            </p>
        </section>

        <!-- Experience Section -->
        <section id="experience">
            <h2>Work Experience</h2>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">Software Engineer</div>
                        <div class="experience-company">Websol.ai | San Antonio, TX</div>
                    </div>
                    <div class="experience-date">Aug 2024 ‚Äì Present</div>
                </div>
                <ul>
                    <li>Architected production data pipelines using Apache Spark (Scala/PySpark) on AWS EMR processing 50K+ daily records with sub-2-minute latency and 99.9% uptime</li>
                    <li>Built RESTful APIs with Spring Boot serving 10K+ requests/day with p99 latency <200ms applying SOLID principles and Resilience4j circuit breakers</li>
                    <li>Implemented real-time streaming with Apache Kafka (3 brokers, 12 partitions) and Apache Airflow orchestration with exactly-once semantics</li>
                    <li>Optimized Trino, StarRocks, and PostgreSQL queries by 60% through indexing strategies, query rewriting, and partition pruning</li>
                    <li>Developed automated data quality frameworks ensuring 98%+ accuracy with anomaly detection and alerting</li>
                </ul>
            </div>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">Graduate Research Assistant</div>
                        <div class="experience-company">Texas A&M University - Kingsville | TX</div>
                    </div>
                    <div class="experience-date">Aug 2023 ‚Äì May 2025</div>
                </div>
                <ul>
                    <li>Completed M.S. in Computer Science (GPA: 3.7/4.0) with specialization in Big Data Analytics and Distributed Systems</li>
                    <li>Conducted research on distributed data processing optimization using Apache Spark, achieving 70% query performance improvement</li>
                    <li>Built production projects on AWS, GCP, and Azure with Apache Airflow DAGs (88+ tasks), Kafka streaming, and Kubernetes auto-scaling</li>
                    <li>Implemented Apache Druid and Trino for real-time OLAP and federated queries achieving <100ms query latency</li>
                    <li>Achieved 85%+ test coverage with comprehensive testing using ScalaTest and unit testing frameworks</li>
                </ul>
            </div>

            <div class="experience-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">Data Engineer</div>
                        <div class="experience-company">HCL Technologies (USAA Client) | Chennai, India</div>
                    </div>
                    <div class="experience-date">Jul 2021 ‚Äì Jul 2023</div>
                </div>
                <ul>
                    <li>Designed and deployed 10+ enterprise-scale ETL pipelines using IBM DataStage and Apache Spark for Fortune 150 banking operations</li>
                    <li>Led migration of 3M+ banking records from legacy mainframe systems with zero data loss and full regulatory compliance</li>
                    <li>Implemented CDC-based real-time replication with HVR, reducing data sync time from hours to minutes</li>
                    <li>Optimized batch processing jobs by 45% through parallel processing patterns and Spark tuning</li>
                    <li>Built PySpark transformations on Hadoop clusters processing 1TB+ daily volumes with distributed computing patterns</li>
                </ul>
            </div>
        </section>

        <!-- Projects Section -->
        <section id="projects">
            <h2>Featured Projects</h2>

            <div class="project-card">
                <h3>IoT Smart City Data Lake & Analytics Platform</h3>
                <p class="project-tech">PySpark | Apache Airflow | Apache Druid | Trino | Delta Lake | Azure Databricks | GCP Dataproc | Spring Boot | Terraform</p>
                
                <div class="project-dataset">
                    <strong>Dataset:</strong> EPA Vehicle Fuel Economy + NHTSA Vehicle Safety Dataset<br>
                    <strong>Scale:</strong> 500K+ vehicles | 100+ attributes | 2M+ events/day
                </div>

                <p class="project-brief">
                    <strong>Overview:</strong> Built a production IoT analytics platform that collects real-time vehicle telemetry data from 500K+ connected vehicles, processes 2M+ sensor events daily, and provides instant insights on fuel efficiency, safety ratings, and predictive maintenance alerts. The system uses a three-tier medallion architecture (Bronze for raw data, Silver for cleaned data, Gold for business analytics) enabling city planners and fleet managers to optimize vehicle operations and reduce maintenance costs.
                </p>

                <ul class="project-highlights">
                    <li><strong>Data Pipeline:</strong> Automated workflow with 88 interdependent Airflow tasks orchestrating data ingestion from Azure Event Hubs (10 partitions processing 1MB/sec), applying 10+ custom transformation functions, and loading into Apache Druid for real-time dashboards accessible to stakeholders</li>
                    <li><strong>Query Performance:</strong> Implemented Apache Druid achieving sub-100ms response times for complex analytical queries; deployed Trino cluster enabling business analysts to query data across Azure, GCP, and PostgreSQL databases using standard SQL without moving data</li>
                    <li><strong>ML Predictive Maintenance:</strong> Developed machine learning models using Spark MLlib (Random Forest + Gradient Boosting algorithms) that predict vehicle component failures with 92% accuracy, enabling proactive maintenance scheduling and reducing unexpected breakdowns by 40%</li>
                    <li><strong>API & Caching Layer:</strong> Built secure REST APIs with OAuth2 authentication for external applications; implemented Redis caching strategy that reduced database load by 60% and improved API response times from 800ms to 150ms</li>
                    <li><strong>Cloud Infrastructure:</strong> Automated multi-cloud deployment using Terraform infrastructure-as-code, implementing auto-scaling policies and cost optimization strategies that reduced monthly cloud expenses by 35% ($2,400/month ‚Üí $1,560/month) while maintaining 99.9% uptime</li>
                </ul>

                <a href="https://github.com/Vikas54-7/iot-smart-city-platform" target="_blank" class="github-link">View on GitHub ‚Üí</a>
            </div>

            <div class="project-card">
                <h3>E-Commerce Real-Time Fraud Detection Pipeline</h3>
                <p class="project-tech">Spark Streaming (Scala) | Apache Kafka | Apache Airflow | StarRocks | Spring Boot | AWS EMR | Azure Databricks | Kubernetes</p>
                
                <div class="project-dataset">
                    <strong>Dataset:</strong> Brazilian E-Commerce Dataset (Kaggle)<br>
                    <strong>Scale:</strong> 500K+ transactions | 25+ features | 100K+ TPS
                </div>

                <p class="project-brief">
                    <strong>Overview:</strong> Developed a real-time fraud detection system that analyzes 100,000+ e-commerce transactions per hour to identify fraudulent purchases before payment processing completes. The system combines rule-based checks (suspicious patterns) with machine learning models to score each transaction's fraud risk in under 200 milliseconds, preventing fraudulent charges while minimizing false positives that would block legitimate customers. Successfully detected 94% of fraud cases while maintaining 87% precision.
                </p>

                <ul class="project-highlights">
                    <li><strong>Real-Time Stream Processing:</strong> Built Apache Kafka streaming pipeline with 3 brokers and 12 partitions processing transactions with exactly-once guarantees, ensuring no transaction is evaluated twice or missed, critical for accurate fraud detection and preventing duplicate charges</li>
                    <li><strong>Query Optimization:</strong> Integrated StarRocks OLAP database with pre-computed materialized views, reducing fraud pattern lookup queries from 8 seconds to 200ms (96% faster), enabling real-time transaction scoring without delaying customer checkout experience</li>
                    <li><strong>Multi-Layer Fraud Scoring:</strong> Engineered intelligent scoring system combining 30% rule-based checks (velocity limits, geo-location anomalies), 35% Random Forest model (purchase pattern analysis), and 35% XGBoost model (behavioral scoring) achieving 94% fraud detection with only 6% false positives</li>
                    <li><strong>Microservices Architecture:</strong> Deployed Spring Boot services with Resilience4j circuit breakers handling 50K+ API requests daily, automatically degrading to cached risk scores when ML models are unavailable, ensuring 99.9% system availability during peak shopping periods</li>
                    <li><strong>Auto-Scaling Infrastructure:</strong> Implemented Kubernetes Horizontal Pod Autoscaler dynamically scaling from 3 to 10 service replicas based on transaction volume, handling Black Friday traffic spikes (5x normal volume) without manual intervention while maintaining sub-100ms response times</li>
                </ul>

                <a href="https://github.com/Vikas54-7/ecommerce-fraud-detection" target="_blank" class="github-link">View on GitHub ‚Üí</a>
            </div>

            <div class="project-card">
                <h3>NYC Taxi Real-Time Analytics Platform</h3>
                <p class="project-tech">PySpark | Apache Kafka | Apache Airflow | Apache Druid | Trino | BigQuery | Spring Boot | GCP Dataproc | Kubernetes | Terraform</p>
                
                <div class="project-dataset">
                    <strong>Dataset:</strong> NYC TLC Trip Records (BigQuery Public Dataset)<br>
                    <strong>Scale:</strong> 1.1 Billion+ trips | 3M+ daily | ~400GB+ compressed
                </div>

                <p class="project-brief">
                    <strong>Overview:</strong> Built an enterprise analytics platform processing 3 million NYC taxi trips daily from 1.1 billion historical records, providing city transportation planners, taxi operators, and data analysts with real-time insights into ride patterns, fare trends, and service quality metrics. The platform combines streaming data from active trips with historical analysis, enabling stakeholders to optimize fleet deployment, predict demand hotspots, and improve service availability across all five NYC boroughs.
                </p>

                <ul class="project-highlights">
                    <li><strong>Scalable Data Infrastructure:</strong> Deployed GCP Dataproc cluster with 10 worker nodes (128GB RAM each) processing 400GB+ of trip data; implemented Apache Kafka with 3 brokers and 24 partitions streaming live trip updates with exactly-once delivery guarantees, ensuring no trip data is lost or duplicated in analytics</li>
                    <li><strong>Sub-Second Query Performance:</strong> Configured Apache Druid OLAP engine achieving 95th percentile query latency under 100ms on 500M+ historical records, enabling business analysts to generate hourly demand reports and fare analysis dashboards in real-time without impacting operational systems</li>
                    <li><strong>Unified Data Access:</strong> Implemented Trino distributed query engine allowing analysts to run single SQL queries across NYC trip data in BigQuery, weather data in AWS S3, and geolocation data in Cloud Storage without complex data movement or ETL jobs, reducing analysis time from hours to minutes</li>
                    <li><strong>Workflow Automation:</strong> Orchestrated 50+ daily Airflow DAGs managing data ingestion, quality validation, aggregation pipelines, and dashboard updates; integrated Great Expectations framework that identified and auto-corrected 2.3M+ data anomalies (invalid GPS coordinates, negative fares) ensuring 99.8% data accuracy</li>
                    <li><strong>High-Availability API Services:</strong> Deployed Spring Boot microservices on Google Kubernetes Engine with 99.95% uptime serving fare prediction and trip analytics APIs; implemented Horizontal Pod Autoscaler dynamically adjusting from 3 to 25 replicas based on traffic, handling morning rush hour query spikes (10x normal load) without performance degradation</li>
                </ul>

                <a href="https://github.com/Vikas54-7/nyc-taxi-analytics" target="_blank" class="github-link">View on GitHub ‚Üí</a>
            </div>
        </section>

        <!-- Skills Section -->
        <section id="skills">
            <h2>Skills & Technologies</h2>
            <div class="skills-grid">
                <div class="skill-category">
                    <h3>Big Data & Streaming</h3>
                    <ul>
                        <li>Apache Spark (PySpark, Scala)</li>
                        <li>Apache Kafka</li>
                        <li>Apache Airflow</li>
                        <li>Apache Druid</li>
                        <li>Hadoop</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Databases & Query Engines</h3>
                    <ul>
                        <li>Trino</li>
                        <li>StarRocks</li>
                        <li>BigQuery</li>
                        <li>PostgreSQL</li>
                        <li>Delta Lake</li>
                        <li>Redis</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Cloud Platforms</h3>
                    <ul>
                        <li>AWS (EMR, S3, Glue, Lambda)</li>
                        <li>GCP (Dataproc, BigQuery)</li>
                        <li>Azure (Databricks, Event Hubs)</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Backend & APIs</h3>
                    <ul>
                        <li>Spring Boot</li>
                        <li>RESTful APIs</li>
                        <li>Microservices</li>
                        <li>OAuth2</li>
                        <li>Resilience4j</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>DevOps & Tools</h3>
                    <ul>
                        <li>Docker & Kubernetes</li>
                        <li>Terraform</li>
                        <li>CI/CD (GitHub Actions)</li>
                        <li>Prometheus & Grafana</li>
                        <li>ELK Stack</li>
                    </ul>
                </div>

                <div class="skill-category">
                    <h3>Programming Languages</h3>
                    <ul>
                        <li>Python</li>
                        <li>Scala</li>
                        <li>Java</li>
                        <li>SQL</li>
                        <li>HCL (Terraform)</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Education Section -->
        <section id="education">
            <h2>Education</h2>
            <div class="education-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">M.S. in Computer and Information Sciences</div>
                        <div class="experience-company">Texas A&M University, Kingsville</div>
                    </div>
                    <div class="experience-date">Aug 2023 ‚Äì May 2025 | GPA: 3.7/4.0</div>
                </div>
                <p><strong>Relevant Coursework:</strong> Advanced Database Systems, Big Data Analytics, Distributed Systems, Cloud Computing Architecture, Machine Learning</p>
            </div>

            <div class="education-item">
                <div class="experience-header">
                    <div>
                        <div class="experience-title">B.Tech in Electronics and Communication Engineering</div>
                        <div class="experience-company">JNTU, India</div>
                    </div>
                    <div class="experience-date">Aug 2017 ‚Äì May 2021</div>
                </div>
            </div>
        </section>

        <!-- Contact Section -->
        <section id="contact">
            <div class="contact-section">
                <h2>Get In Touch</h2>
                <p style="margin: 20px 0;">I'm actively seeking opportunities in data engineering and distributed systems roles. Let's connect!</p>
                <div class="contact-links">
                    <a href="mailto:pabba.vikas54@gmail.com">Email Me</a>
                    <a href="https://www.linkedin.com/in/pabbavikas/" target="_blank">LinkedIn</a>
                    <a href="https://github.com/Vikas54-7" target="_blank">GitHub</a>
                </div>
                <p style="margin-top: 2rem; font-size: 1.1rem;">üìç San Antonio, TX | üìû (210) 873-7446</p>
            </div>
        </section>
    </div>

    <!-- Footer -->
    <footer>
        <p>¬© 2025 Vikas Pabba. Built with HTML, CSS, and 
